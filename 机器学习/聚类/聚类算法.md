### 聚类算法

常见聚类算法分为Kmeans、层次聚类、DBSCAN聚类、高斯混合模型（GMM）

K-means、层次聚类、DBSCAN和高斯混合模型（GMM）都是常用的聚类算法，各有其特点和适用场景。

### K-means

**原理**: 将数据分成K个簇，每个簇由其质心（即簇内点的均值）代表，目标是最小化每个点到其质心的距离的总和。

**优点**:

- 计算效率较高，适合处理大型数据集。
- 实现简单，广泛应用于各种问题。

**缺点**:

- 需要预先指定簇的数量K。
- 假设簇为凸形状，可能不适合识别非球形簇。
- 对初始质心选择敏感，可能陷入局部最优解。
- 对噪声和离群点敏感。

### 层次聚类

**原理**: 通过逐步合并最近的簇（凝聚层次聚类）或逐步分割簇（分裂层次聚类）来构建一个簇的层次结构。

**优点**:

- 不需要预先指定簇的数量。
- 可以通过树状图（dendrogram）直观地展示簇的形成过程。
- 能够发现数据的层次结构。

**缺点**:

- 计算复杂度高，不适合大规模数据集。
- 簇一旦合并或分裂就不能更改，对噪声和离群点敏感。

### DBSCAN

**原理**: 基于密度的聚类算法，根据核心点、边界点和噪声点的概念来识别簇。簇定义为由足够密集的点组成的区域。

**优点**:

- 不需要预先指定簇的数量。
- 可以识别任意形状的簇。
- 对噪声和离群点具有良好的鲁棒性。

**缺点**:

- 对输入参数（邻域大小`eps`和最小点数`minPts`）敏感。
- 当簇的密度变化很大时，性能可能下降。

### 高斯混合模型（GMM）

**原理**: 假设数据是从多个高斯分布的混合中生成的。每个分布对应一个簇，簇的形状由其均值和协方差决定。

**优点**:

- 提供了软聚类（即给出样本属于各簇的概率）。
- 灵活性高，可以捕捉簇的椭圆形状。
- 作为一种概率模型，可以用来估计数据的分布。

**缺点**:

- 需要预先指定成分（即高斯分布）的数量。
- 对初始参数选择敏感。
- 可能在高维数据上表现不佳。

### 对比总结

- **K-means** 和 **GMM** 都需要预先指定簇的数量，但GMM提供了更丰富的信息，适合于簇形状和大小各异的情况，而K-means更适合圆形簇和大规模数据。
- **层次聚类** 提供了簇之间关系的洞见，适合于小规模数据集或者当我们需要了解数据层次结构时。
- **DBSCAN** 不需要预先指定簇的数量



在聚类分析中，最常用的评估指标是轮廓系数（Silhouette Coefficient）。轮廓系数综合考虑了簇内的紧密度和簇间的分离度，易于计算和解释，因此被广泛应用于聚类性能的评估。

轮廓系数的取值范围在[-1, 1]之间，越接近1表示聚类结果越好，越接近-1表示聚类结果越差，接近0表示存在重叠或边界模糊的情况。



在kmeans算法中，一般用肘部法则来确定最优聚类数k：

![](C:\Users\Morty\Downloads\肘部法.png)

上面这张图的最佳簇为4



实战：

| Sex  | Height(cm) | Weight(kg) |
| ---- | ---------- | ---------- |
| 0    | 156        | 50         |
| 0    | 160        | 60         |
| 0    | 162        | 54         |
| 0    | 162        | 55         |
| 0    | 160.5      | 56         |
| 0    | 160        | 53         |
| 0    | 158        | 55         |
| 0    | 164        | 60         |
| 0    | 165        | 50         |
| 0    | 166        | 55         |
| 0    | 158        | 47.5       |
| 0    | 161        | 49         |
| 0    | 169        | 55         |
| 0    | 161        | 46         |
| 0    | 160        | 45         |
| 0    | 167        | 44         |
| 0    | 155        | 49         |
| 0    | 154        | 57         |
| 0    | 172        | 52         |
| 0    | 155        | 56         |
| 0    | 157        | 55         |
| 0    | 165        | 65         |
| 0    | 156        | 52         |
| 0    | 155        | 50         |
| 0    | 156        | 56         |
| 0    | 160        | 55         |
| 0    | 158        | 55         |
| 0    | 162        | 70         |
| 0    | 162        | 65         |
| 0    | 155        | 57         |
| 0    | 163        | 70         |
| 0    | 160        | 60         |
| 0    | 162        | 55         |
| 0    | 165        | 65         |
| 0    | 159        | 60         |
| 0    | 147        | 47         |
| 0    | 163        | 53         |
| 0    | 157        | 54         |
| 0    | 160        | 55         |
| 0    | 162        | 48         |
| 0    | 158        | 60         |
| 0    | 155        | 48         |
| 0    | 165        | 60         |
| 0    | 161        | 58         |
| 0    | 159        | 45         |
| 0    | 163        | 50         |
| 0    | 158        | 49         |
| 0    | 155        | 50         |
| 0    | 162        | 55         |
| 0    | 157        | 63         |
| 0    | 159        | 49         |
| 0    | 152        | 47         |
| 0    | 156        | 51         |
| 0    | 165        | 49         |
| 0    | 154        | 47         |
| 0    | 156        | 52         |
| 0    | 162        | 48         |
| 1    | 162        | 60         |
| 1    | 164        | 62         |
| 1    | 168        | 86         |
| 1    | 187        | 75         |
| 1    | 167        | 75         |
| 1    | 174        | 64         |
| 1    | 175        | 62         |
| 1    | 170        | 65         |
| 1    | 176        | 73         |
| 1    | 169        | 58         |
| 1    | 178        | 54         |
| 1    | 165        | 66         |
| 1    | 183        | 68         |
| 1    | 171        | 61         |
| 1    | 179        | 64         |
| 1    | 172        | 60         |
| 1    | 173        | 59         |
| 1    | 172        | 58         |
| 1    | 175        | 62         |
| 1    | 160        | 60         |
| 1    | 160        | 58         |
| 1    | 160        | 60         |
| 1    | 175        | 75         |
| 1    | 163        | 60         |
| 1    | 181        | 77         |
| 1    | 172        | 80         |
| 1    | 175        | 73         |
| 1    | 175        | 60         |
| 1    | 167        | 65         |
| 1    | 172        | 60         |
| 1    | 169        | 75         |
| 1    | 172        | 65         |
| 1    | 175        | 72         |
| 1    | 172        | 60         |
| 1    | 170        | 65         |
| 1    | 158        | 59         |
| 1    | 167        | 63         |
| 1    | 164        | 61         |
| 1    | 176        | 65         |
| 1    | 182        | 95         |
| 1    | 173        | 75         |
| 1    | 176        | 67         |
| 1    | 163        | 58         |
| 1    | 166        | 67         |
| 1    | 162        | 59         |
| 1    | 169        | 56         |
| 1    | 163        | 59         |
| 1    | 163        | 56         |
| 1    | 176        | 62         |
| 1    | 169        | 57         |
| 1    | 173        | 61         |
| 1    | 163        | 59         |
| 1    | 167        | 57         |
| 1    | 176        | 63         |
| 1    | 168        | 61         |
| 1    | 167        | 60         |
| 1    | 170        | 69         |

数据如上:

第一种聚类是把性别也加入：

```python
from sklearn.preprocessing import StandardScaler

# 创建标准化器
scaler = StandardScaler()

# 选择要标准化的特征
X_to_scale = data[['Height(cm)', 'Weight(kg)']]

# 对选定的特征进行标准化
X_scaled = scaler.fit_transform(X_to_scale)

# 创建新的特征数据集，包括原始的'Sex'特征和标准化后的特征
X_normalized = pd.concat([data['Sex'], pd.DataFrame(X_scaled, columns=['Height_scaled', 'Weight_scaled'])], axis=1)
```

```python
# 创建k-means聚类模型
kmeans = KMeans(n_clusters=2, random_state=42)

# 对标准化后的数据进行聚类
kmeans_labels = kmeans.fit_predict(X_normalized)

# 计算k-means的轮廓系数评分
kmeans_score = silhouette_score(X_normalized, kmeans_labels)
0.4580980559875068
```

```python
# 执行GMM聚类
gmm = GaussianMixture(n_components=2, random_state=42)
gmm_labels = gmm.fit_predict(X_normalized)
# 计算gmm的轮廓系数评分
gmm_score = silhouette_score(X_normalized, gmm_labels)
0.42449743338248974
```

```python
# 执行DBSCAN聚类
dbscan = DBSCAN(eps=1, min_samples=5)   
dbscan_labels = dbscan.fit_predict(X_normalized)
dbscan_score = silhouette_score(X_normalized, dbscan_labels)
0.5750750646910631
```

```python
from sklearn.cluster import AgglomerativeClustering
# 创建层次聚类模型
agg_clustering = AgglomerativeClustering(n_clusters=2)

# 对特征数据进行聚类
agg_labels = agg_clustering.fit_predict(X_normalized)
agg_score = silhouette_score(X_normalized, agg_labels)
0.4263471098226299
```

在本例中，DBSCAN表现最好，但是需要调参。